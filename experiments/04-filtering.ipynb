{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from misc import HUF_TOKEN\n",
    "from misc import ALL_ASSIGNMENTS_PATHS, ALL_N_CLUSTERS, FILTER_PATH\n",
    "\n",
    "from dataset import load_comparison_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0be3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, _, _, _, _ = load_comparison_dataset(token=HUF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assignments = [np.load(path) for path in ALL_ASSIGNMENTS_PATHS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df37f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteredBradleyTerryModel(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_items: int,\n",
    "            n_clusters: int,\n",
    "            advantage: bool = False,\n",
    "            reg: float = 1e-2,\n",
    "    ):\n",
    "        super(ClusteredBradleyTerryModel, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        self.n_clusters = n_clusters\n",
    "        self.reg = reg\n",
    "        self.advantage = advantage\n",
    "\n",
    "        # Bradley-Terry for item-item preferences\n",
    "        self.bt_item_popularity = nn.Parameter(torch.zeros(n_clusters, n_items))\n",
    "\n",
    "        # Per-cluster advantage terms\n",
    "        if advantage:\n",
    "            self.bt_adv = nn.Parameter(torch.zeros(n_clusters,))\n",
    "\n",
    "    def predict_proba(\n",
    "            self,\n",
    "            cluster_indices,\n",
    "            item_i_indices,\n",
    "            item_j_indices,\n",
    "    ):\n",
    "        H = self.forward(\n",
    "            cluster_indices,\n",
    "            item_i_indices,\n",
    "            item_j_indices,\n",
    "        )\n",
    "        pj = torch.sigmoid(H)\n",
    "        pi = 1 - pj\n",
    "        return torch.stack([pi, pj], dim=1)\n",
    "    \n",
    "    def forward(\n",
    "            self,\n",
    "            cluster_indices,\n",
    "            item_i_indices,\n",
    "            item_j_indices,\n",
    "    ):\n",
    "        Z_i = self.bt_item_popularity[cluster_indices, item_i_indices]\n",
    "        Z_j = self.bt_item_popularity[cluster_indices, item_j_indices]  # (n_samples,)\n",
    "        H = Z_j - Z_i\n",
    "\n",
    "        if self.advantage:\n",
    "            H += self.bt_adv[cluster_indices]\n",
    "\n",
    "        return H\n",
    "    \n",
    "    def loss(\n",
    "            self,\n",
    "            cluster_indices,\n",
    "            item_i_indices,\n",
    "            item_j_indices,\n",
    "            y,\n",
    "    ):\n",
    "        # Log likelihoods\n",
    "        H = self.forward(\n",
    "            cluster_indices,\n",
    "            item_i_indices,\n",
    "            item_j_indices,\n",
    "        )\n",
    "        bt_loss = F.binary_cross_entropy_with_logits(H, y)\n",
    "\n",
    "        # Regularization\n",
    "        reg_loss = self.reg * (\n",
    "            self.bt_item_popularity.norm(p=2).abs()\n",
    "        ) / self.n_clusters\n",
    "\n",
    "        return bt_loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e377e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cluster_bt(\n",
    "        cluster_indices: torch.Tensor,\n",
    "        item_i_indices: torch.Tensor,\n",
    "        item_j_indices: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        bt_max_steps: int = 1000,\n",
    "        progress_bar: bool = True,\n",
    "        advantage: bool = False,\n",
    "):\n",
    "    n_items = max(item_i_indices.max(), item_j_indices.max()).item() + 1\n",
    "    assignments = cluster_indices\n",
    "    n_clusters = cluster_indices.max() + 1\n",
    "\n",
    "    # Initialize Bradley-Terry model\n",
    "    model = ClusteredBradleyTerryModel(\n",
    "        n_items=n_items,\n",
    "        n_clusters=n_clusters,\n",
    "        advantage=advantage,\n",
    "    ).to(item_i_indices.device)\n",
    "\n",
    "    # Fit Bradley-Terry parameters\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), max_iter=bt_max_steps, line_search_fn=\"strong_wolfe\", tolerance_grad=1e-09)\n",
    "\n",
    "    if progress_bar:\n",
    "        prog = tqdm(range(bt_max_steps), desc=\"Fitting BT parameters\")\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(\n",
    "            assignments[assignments >= 0],\n",
    "            item_i_indices[assignments >= 0],\n",
    "            item_j_indices[assignments >= 0],\n",
    "            y[assignments >= 0],\n",
    "        )\n",
    "        loss.backward()\n",
    "        if progress_bar:\n",
    "            prog.update(1)\n",
    "            prog.set_postfix(loss=loss.item())\n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(closure)\n",
    "\n",
    "    if progress_bar:\n",
    "        prog.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = max(D[\"item_i_indices\"].max(), D[\"item_j_indices\"].max()).item() + 1\n",
    "item_i_indices = D[\"item_i_indices\"]\n",
    "item_j_indices = D[\"item_j_indices\"]\n",
    "y = D[\"y\"]\n",
    "\n",
    "def get_pref_matrix(model):\n",
    "    P = torch.zeros((n_clusters, m, m))\n",
    "    for c in range(n_clusters):\n",
    "        item_indices = torch.arange(m)\n",
    "        cluster_indices = torch.full((m * m,), c, dtype=torch.long)\n",
    "        item_j_expanded = item_indices.repeat_interleave(m)\n",
    "        item_i_expanded = item_indices.repeat(m)\n",
    "        P_c = model.predict_proba(\n",
    "            cluster_indices,\n",
    "            item_i_expanded,\n",
    "            item_j_expanded,\n",
    "        )[:, 1].view(m, m)\n",
    "        P[c] = P_c\n",
    "    return P.detach().numpy()\n",
    "\n",
    "P0s = []\n",
    "P1s = []\n",
    "for n_clusters, assignments in zip(ALL_N_CLUSTERS, all_assignments):\n",
    "    print(f\"Processing n_clusters={n_clusters}...\")\n",
    "    model_0 = fit_cluster_bt(\n",
    "        cluster_indices=torch.tensor(assignments, dtype=torch.long),\n",
    "        item_i_indices=D[\"item_i_indices\"],\n",
    "        item_j_indices=D[\"item_j_indices\"],\n",
    "        y=D[\"y\"],\n",
    "        advantage=False,\n",
    "    )\n",
    "    model_1 = fit_cluster_bt(\n",
    "        cluster_indices=torch.tensor(assignments, dtype=torch.long),\n",
    "        item_i_indices=D[\"item_i_indices\"],\n",
    "        item_j_indices=D[\"item_j_indices\"],\n",
    "        y=D[\"y\"],\n",
    "        advantage=True,\n",
    "    )\n",
    "    P0s.append(get_pref_matrix(model_0))\n",
    "    P1s.append(get_pref_matrix(model_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fe3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MLEs of preference matrices\n",
    "PSs = []\n",
    "for n_clusters, assignments in zip(ALL_N_CLUSTERS, all_assignments):\n",
    "    assignments = torch.tensor(assignments, dtype=torch.long)\n",
    "    W = torch.zeros((n_clusters, m, m))\n",
    "    L = torch.zeros((n_clusters, m, m))\n",
    "    W.index_put_((assignments, item_i_indices, item_j_indices), (y == 0.0).float(), accumulate=True)\n",
    "    L.index_put_((assignments, item_i_indices, item_j_indices), (y == 1.0).float(), accumulate=True)\n",
    "    PS = (W + L.transpose(1, 2)) / (W + W.transpose(1, 2) + + L + L.transpose(1, 2) + 1e-8)\n",
    "    PS = PS.numpy()\n",
    "    PSs.append(PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0585332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute per-cluster log-likelihoods\n",
    "def pref_loglik(P, n_clusters, assignments):\n",
    "    loglik = []\n",
    "    for c in range(n_clusters):\n",
    "        cluster_filt = (assignments == c)\n",
    "        y_clust = y[cluster_filt].numpy()\n",
    "        p_clust = P[c, item_j_indices[cluster_filt].numpy(), item_i_indices[cluster_filt].numpy()]\n",
    "        loglik.append((y_clust * np.log(p_clust + 1e-8) + (1 - y_clust) * np.log(1 - p_clust + 1e-8)).sum())\n",
    "    return np.array(loglik) \n",
    "\n",
    "ll0s = []\n",
    "ll1s = []\n",
    "llSs = []\n",
    "for n_clusters, assignments, P0, P1, PS in zip(ALL_N_CLUSTERS, all_assignments, P0s, P1s, PSs):\n",
    "    ll0 = pref_loglik(P0, n_clusters, assignments)\n",
    "    ll1 = pref_loglik(P1, n_clusters, assignments)\n",
    "    llS = pref_loglik(PS, n_clusters, assignments)\n",
    "    ll0s.append(ll0)\n",
    "    ll1s.append(ll1)\n",
    "    llSs.append(llS)\n",
    "\n",
    "ll0s[-1].mean(), ll1s[-1].mean(), llSs[-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bc376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate 95% chi-squared threshold\n",
    "from scipy.stats import chi2\n",
    "chi2_threshold_0v1 = chi2.ppf(0.95, df=1)\n",
    "chi2_threshold_0vS = chi2.ppf(0.95, df=m*(m-3)/2)\n",
    "chi2_threshold_0v1, chi2_threshold_0vS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute per-cluster likelihood ratio statistics\n",
    "lr_0v1s = []\n",
    "lr_0vSs = []\n",
    "for ll0, ll1, lls in zip(ll0s, ll1s, llSs):\n",
    "    lr_0v1 = 2 * (ll1 - ll0)\n",
    "    lr_0vS = 2 * (lls - ll0)\n",
    "    lr_0v1s.append(lr_0v1)\n",
    "    lr_0vSs.append(lr_0vS)\n",
    "(lr_0v1s[-1] > chi2_threshold_0v1).mean(), (lr_0vSs[-1] > chi2_threshold_0vS).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_0vS_color = \"#7EC8E3\"\n",
    "T_0v1_color = \"#FF7F0E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d257bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array([np.mean(b) for b in lr_0vSs])\n",
    "ci_low = np.array([np.percentile(b, 2.5) for b in lr_0vSs])\n",
    "ci_high = np.array([np.percentile(b, 97.5) for b in lr_0vSs])\n",
    "yerr = np.vstack([means - ci_low, ci_high - means])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "log_x = np.log10(ALL_N_CLUSTERS)\n",
    "log_width = 0.1\n",
    "\n",
    "left  = 10 ** (log_x - log_width/2)\n",
    "right = 10 ** (log_x + log_width/2)\n",
    "bar_widths = right - left\n",
    "\n",
    "ax.bar(\n",
    "    ALL_N_CLUSTERS,\n",
    "    means,\n",
    "    yerr=yerr,\n",
    "    color=T_0vS_color,\n",
    "    edgecolor=\"none\",\n",
    "    capsize=4,\n",
    "    width=bar_widths,\n",
    ")\n",
    "\n",
    "ax.axhline(\n",
    "    y=chi2_threshold_0vS,\n",
    "    color=T_0vS_color,\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Critical Value (α=0.05)\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(ALL_N_CLUSTERS)\n",
    "ax.set_xticklabels([str(c) for c in ALL_N_CLUSTERS])\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlabel(\"Number of Clusters\")\n",
    "ax.set_ylabel(\"Likelihood Ratio Statistic\")\n",
    "ax.set_title(\"Likelihood Ratio Statistics by Number of Clusters\")\n",
    "\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.grid(axis=\"y\", linestyle=\":\", alpha=0.5)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea395e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = (assignments[:, None] == torch.arange(n_clusters)).sum(dim=0).numpy()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(cluster_sizes[1:], lr_0v1s[-1][1:], alpha=0.7, label=\"BT vs. BT+Adv [df=1]\", s=8, color=T_0v1_color)\n",
    "plt.scatter(cluster_sizes[1:], lr_0vSs[-1][1:], alpha=0.7, label=\"BT vs. Saturated [df=m(m-3)/2]\", s=8, color=T_0vS_color)\n",
    "\n",
    "# Add horizontal line for critical value\n",
    "plt.axhline(y=chi2_threshold_0v1, linestyle='--', label='Critical Value (α=0.05)', color=T_0v1_color)\n",
    "plt.axhline(y=chi2_threshold_0vS, linestyle='--', label='Critical Value (α=0.05)', color=T_0vS_color)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Cluster Size (log scale)\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Likelihood Ratio Test Statistic\")\n",
    "plt.title(\"Likelihood Ratio Test Statistic vs Cluster Size\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e71907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bt_fisher_information_trace(\n",
    "    theta: torch.Tensor,\n",
    "    item_i_indices: torch.Tensor,\n",
    "    item_j_indices: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    theta = theta.to(dtype=torch.float64)\n",
    "    i = item_i_indices.long()\n",
    "    j = item_j_indices.long()\n",
    "\n",
    "    delta = theta[i] - theta[j]\n",
    "    p = torch.sigmoid(delta)\n",
    "    w = p * (1.0 - p)\n",
    "    return 2.0 * w.sum()\n",
    "\n",
    "n_clusters = ALL_N_CLUSTERS[-1]\n",
    "assignments = all_assignments[-1]\n",
    "model_0 = fit_cluster_bt(\n",
    "    cluster_indices=torch.tensor(assignments, dtype=torch.long),\n",
    "    item_i_indices=D[\"item_i_indices\"],\n",
    "    item_j_indices=D[\"item_j_indices\"],\n",
    "    y=D[\"y\"],\n",
    "    advantage=False,\n",
    ")\n",
    "theta = model_0.bt_item_popularity.detach()\n",
    "\n",
    "I = []\n",
    "for c in range(n_clusters):\n",
    "    cluster_filt = (assignments == c)\n",
    "    item_i_clust = item_i_indices[cluster_filt]\n",
    "    item_j_clust = item_j_indices[cluster_filt]\n",
    "    I_c = bt_fisher_information_trace(\n",
    "        theta[c],\n",
    "        item_i_clust,\n",
    "        item_j_clust,\n",
    "    )\n",
    "    I.append(I_c.item())\n",
    "I = np.array(I)\n",
    "I.min(), np.median(I), I.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e918a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fisher information vs. 0 vs S likelihood ratio statistic\n",
    "lr_0vS = lr_0vSs[-1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(I, lr_0vS, color=T_0vS_color, s=3, alpha=0.7)\n",
    "plt.axhline(y=chi2_threshold_0vS, linestyle='--', label='Critical Value (α=0.05)', color=T_0vS_color)\n",
    "plt.xlabel(\"Information Trace\")\n",
    "plt.ylabel(\"Likelihood Ratio Test Statistic\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"Fisher Information vs. BT vs. Saturated Likelihood Ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_0v1 = lr_0v1s[-1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(I, lr_0v1, color=T_0v1_color, s=3, alpha=0.7)\n",
    "plt.axhline(y=chi2_threshold_0v1, linestyle='--', label='Critical Value (α=0.05)', color=T_0v1_color)\n",
    "plt.xlabel(\"Information Trace\")\n",
    "plt.ylabel(\"Likelihood Ratio Test Statistic\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"Fisher Information vs. BT vs. BT+Adv Likelihood Ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ce51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = ALL_N_CLUSTERS[-1]\n",
    "I = I\n",
    "lr_0v1 = lr_0v1s[-1]\n",
    "lr_0vS = lr_0vSs[-1]\n",
    "filt = (I >= 1) & (lr_0v1 <= chi2_threshold_0v1) & (lr_0vS <= 1.2)\n",
    "np.save(FILTER_PATH, filt)\n",
    "print(f\"Filtering to {filt.sum()} homogeneous clusters, from {n_clusters} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import TOPICS_PATH\n",
    "import json\n",
    "\n",
    "topics = [\"\"] * n_clusters\n",
    "with open(TOPICS_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        cluster_idx = entry[\"gid\"]\n",
    "        topic = entry[\"topic\"]\n",
    "        topics[cluster_idx] = topic\n",
    "\n",
    "np.random.seed(0)\n",
    "homogeneous_cluster_indices = np.where(filt)[0]\n",
    "heterogeneous_cluster_indices = np.where(~filt)[0]\n",
    "sampled_homogeneous_cluster_indices = np.random.choice(\n",
    "    homogeneous_cluster_indices,\n",
    "    size=min(10, len(homogeneous_cluster_indices)),\n",
    "    replace=False,\n",
    ")\n",
    "sampled_heterogeneous_cluster_indices = np.random.choice(\n",
    "    heterogeneous_cluster_indices,\n",
    "    size=min(10, len(heterogeneous_cluster_indices)),\n",
    "    replace=False,\n",
    ")\n",
    "\n",
    "print(f\"Sampled homogeneous cluster topics: {[topics[i] for i in sampled_homogeneous_cluster_indices]}\")\n",
    "print(f\"Sampled heterogeneous cluster topics: {[topics[i] for i in sampled_heterogeneous_cluster_indices]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28abc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "def expected_conditional_J(theta_p, theta_q):\n",
    "    \"\"\"Expected conditional Jeffreys divergence between two BT models.\"\"\"\n",
    "    Lp = theta_p[:, None] - theta_p[None, :]\n",
    "    Lq = theta_q[:, None] - theta_q[None, :]\n",
    "    P = expit(Lp)\n",
    "    Q = expit(Lq)\n",
    "    J = (P - Q) * (Lp - Lq)\n",
    "    iu = np.triu_indices_from(J, k=1)\n",
    "    return np.mean(J[iu])\n",
    "\n",
    "def pairwise_divergence_matrix(thetas):\n",
    "    C = len(thetas)\n",
    "    D = np.zeros((C, C))\n",
    "    for i in range(C):\n",
    "        for j in range(i + 1, C):\n",
    "            d = expected_conditional_J(thetas[i], thetas[j])\n",
    "            D[i, j] = D[j, i] = d\n",
    "    return D\n",
    "\n",
    "def embed_clusters_from_divergence(D, n_components=2, random_state=0):\n",
    "    mds = MDS(n_components=n_components, dissimilarity='precomputed',\n",
    "              random_state=random_state)\n",
    "    return mds.fit_transform(D)   # (C, 2)\n",
    "\n",
    "def plot_cluster_embedding(coords, topics):\n",
    "    coords = np.asarray(coords)\n",
    "    x, y = coords[:, 0], coords[:, 1]\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "    # Points with your theme color\n",
    "    ax.scatter(x, y, s=60, alpha=0.9,\n",
    "               edgecolors=\"#3A4A5A\", linewidths=0.8,\n",
    "               color=\"#7EC8E3\")\n",
    "\n",
    "    # Vertical offset so text is above points, not on top\n",
    "    y_span = y.max() - y.min() if y.max() > y.min() else 1.0\n",
    "    y_off = 0.015 * y_span  # 0.8% of span\n",
    "\n",
    "    for i, txt in enumerate(topics):\n",
    "        ax.text(\n",
    "            x[i], y[i] + y_off,\n",
    "            txt,\n",
    "            fontsize=12,\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    ax.set_title(\"Cluster Embedding from Jeffreys Divergence\", fontsize=14, pad=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_frame_on(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "bt_params = model_0.bt_item_popularity.detach().cpu().numpy()[homogeneous_cluster_indices]\n",
    "D = pairwise_divergence_matrix(bt_params)\n",
    "coords = embed_clusters_from_divergence(D)\n",
    "plot_cluster_embedding(coords, [topics[c] for c in homogeneous_cluster_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import load_embeddings\n",
    "\n",
    "emb = load_embeddings()\n",
    "centers = []\n",
    "for c in homogeneous_cluster_indices:\n",
    "    center = emb[assignments == c].mean(axis=0)\n",
    "    centers.append(center)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(centers)):\n",
    "    for j in range(i + 1, len(centers)):\n",
    "        sim = F.cosine_similarity(\n",
    "            torch.tensor(centers[i]).unsqueeze(0),\n",
    "            torch.tensor(centers[j]).unsqueeze(0),\n",
    "        ).item()\n",
    "        x.append(D[i, j])\n",
    "        y.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3023119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R squared\n",
    "x_np = np.array(x)\n",
    "y_np = np.array(y)\n",
    "correlation_matrix = np.corrcoef(x_np, y_np)\n",
    "correlation_xy = correlation_matrix[0, 1]\n",
    "r_squared = correlation_xy**2\n",
    "print(f\"R squared between divergence and embedding similarity: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot divergence vs. embedding similarity\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, color=\"green\", s=5, alpha=0.7)\n",
    "\n",
    "# Add R squared annotation\n",
    "plt.text(0.05, 0.95, f\"$R^2$ = {r_squared:.4f}\", transform=plt.gca().transAxes,\n",
    "         fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.5))\n",
    "\n",
    "plt.xlabel(\"Expected Conditional Jeffreys Divergence\")\n",
    "plt.ylabel(\"Embedding Cosine Similarity\")\n",
    "plt.title(\"Cluster Divergence vs. Embedding Similarity\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
